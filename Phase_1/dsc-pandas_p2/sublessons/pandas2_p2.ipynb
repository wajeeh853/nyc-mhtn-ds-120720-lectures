{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Pandas, Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring back in our Austin Animal Shelter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "from src.student_caller import three_random_students\n",
    "from src.student_list import student_list\n",
    "url = 'https://data.austintexas.gov/resource/9t4d-g238.json'\n",
    "response = requests.get(url)\n",
    "animals = pd.DataFrame(response.json())\n",
    "animals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those of you familiar with Excel have probably used Pivot Tables. Pandas has a similar functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by two different columns can be very helpful, but it has the unsavory side effect of creating a two-level index. This can be a good time to use `.pivot()` or `.pivot_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from previous notebook to convert age string to days upon outcome\n",
    "\n",
    "def age_to_days(age):\n",
    "    \n",
    "    '''\n",
    "    params: age upon outcome of shelter animal. \n",
    "    A number followed by a unit of time \n",
    "    'NULL', 'days', 'month', 'months', 'week', 'weeks', 'year', 'years'\n",
    "    \n",
    "    returns: days old at outcome\n",
    "    '''\n",
    "    \n",
    "    age_split = age.split(' ')\n",
    "    \n",
    "    if len(age_split)  == 1:\n",
    "        return np.nan\n",
    "    \n",
    "    elif age_split[1] == 'days' :\n",
    "        return int(age_split[0])\n",
    "    \n",
    "    elif age_split[1] in (['month' or 'months']):\n",
    "        return int(age_split[0]) * 30\n",
    "    \n",
    "    elif age_split[1] in ['week' or 'weeks'] :\n",
    "        return int(age_split[0]) * 7\n",
    "    \n",
    "    else:\n",
    "        return int(age_split[0]) * 365\n",
    "    \n",
    "    \n",
    "animals['days_upon_outcome'] = animals['age_upon_outcome'].apply(age_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.groupby(by=['outcome_type', 'sex_upon_outcome']).agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.pivot_table(index='outcome_type', columns='sex_upon_outcome', aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for Combining DataFrames: .join(), .merge(), .concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has several methods to combine dataframes.  The first two, join and merge, and very similar.  Here is a nice [Stack Overflow](https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas) response about the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join, by default, combines two dataframes based on their **index**, and performs a **left join**.\n",
    "\n",
    "![images](images/left_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy1 = pd.DataFrame([[63, 142], [33, 47], [70, 20]], columns=['age', 'HP'])\n",
    "toy2 = pd.DataFrame([[63, 100], [33, 200]], columns=['age', 'MP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy1.set_index('age').join(toy2.set_index('age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on this method, check out the [doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge performs a bit differently.  We have to provide specific indices to merge on.  It is more typing, but gives us more control. By default it performs an **inner join**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inner_join](images/inner_join.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chars = pd.read_csv('ds_chars.csv', index_col=0)\n",
    "ds_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('states.csv', index_col=0)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chars.merge(states, left_on='home_state', right_on='state', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a *list* of pandas objects as arguments.\n",
    "It essentially pastes two dataframes together in the order that it encounters the records.\n",
    "\n",
    "N.B. The cell below may produce a **Deprecation Warning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = pd.concat([ds_chars, states])\n",
    "ds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat()`––and many other pandas operations––make use of an `axis` parameter. For this particular method I need to specify whether I want to concatenate the DataFrames *row-wise* (`axis=0`) or *column-wise* (`axis=1`). The default is `axis=0`, so let's override that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Use of Categories: One-Hot Encoding\n",
    "\n",
    "OHE is a data transformation which will become much more important when we are building models. It sometimes is a bit tricky to get our heads around, so we will introduce it now.\n",
    "\n",
    "One hot encoding takes as input a categorical feature, such as animal_type. It then uses the values of feature as headers of columns, and inserts 1 as a value in the column which represents the rows true category.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(animals['animal_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dummies has a key parameter, `drop_first`, which drops the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(animals['animal_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge check: Although we dropped the Bird column, we can still tell which records are birds.  How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_random_students(student_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If however we're in a later stage of the process and we're interested, say, in preparing a data pipeline, `pandas.get_dummies()` will prove inferior to other tools.\n",
    "\n",
    "In practice, we will **not** use `pandas.get_dummies()`. The library Scikit-Learn (`sklearn`, included with your Anaconda installation) has a `OneHotEncoder` class that creates an object that persists. This makes it much more apt for production environments, and so it's good to get in the habit of using it.\n",
    "\n",
    "Ultimately, we will use **many** tools from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohe.fit(animals[['animal_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `OneHotEncoder` has been fitted to our data, it has newly available attributes and methods. In particular, it has access to the different categories that we're replacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have much more to say about `sklearn` syntax and about Python's object structure. But let's now transform our data to see what the new table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(animals[['animal_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of saving storage space, the return is a **sparse matrix**, but we can \"re-inflate it if we want to see it in tabular form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_encoded = ohe.transform(animals[['animal_type']]).todense()\n",
    "types_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(types_encoded, columns=ohe.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
